from flask import Flask, render_template, request, send_file, redirect, url_for
import joblib
import pandas as pd
import json
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from catboost import CatBoostClassifier, Pool
import joblib
import io
import os
import uuid

import google.generativeai as genai


app = Flask(__name__)
app.config["MAX_CONTENT_LENGTH"] = 16 * 1024 * 1024  # 16MB
app.config["UPLOAD_FOLDER"] = "temp"


@app.route("/", methods=["GET"])
def index():
    return render_template("index.html")


@app.route("/result", methods=["GET"])
def result():
    return render_template("resultPage.html")


@app.route("/about", methods=["GET"])
def about():
    return render_template("about.html")


@app.route("/kmeans-analyze", methods=["GET", "POST"])
def kmeans_analyze():
    if request.method == "POST":
        file = request.files["file"]
        session_id = str(uuid.uuid4())

        if file.filename.endswith(".csv"):
            df = pd.read_csv(file)
        elif file.filename.endswith((".xlsx", ".xls")):
            df = pd.read_excel(file)
        else:
            return "‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"

        df_pre = preprocess_for_kmeans(df)
        silhouette_scores = {}
        elbow_ks = list(range(1, 11))
        distortions = []

        for k in elbow_ks:
            model = KMeans(
                n_clusters=k, init="k-means++", max_iter=300, n_init=10, random_state=42
            )
            model.fit(df_pre)
            distortions.append(model.inertia_)

        for k in [3, 4]:
            model = KMeans(n_clusters=k, max_iter=50, random_state=42, n_init=10)

            labels = model.fit_predict(df_pre)
            silhouette_scores[k] = silhouette_score(df_pre, labels)

        # Save elbow graph
        plt.figure()
        plt.plot(elbow_ks, distortions, "bx-")
        plt.xlabel("k")
        plt.ylabel("Distortion")
        plt.title("Elbow Method")
        elbow_path = f"static/images/elbow_{session_id}.png"
        plt.savefig(elbow_path)
        plt.close()

        # Save raw file to temp
        filepath = os.path.join(app.config["UPLOAD_FOLDER"], f"{session_id}.csv")
        os.makedirs(app.config["UPLOAD_FOLDER"], exist_ok=True)
        df.to_csv(filepath, index=False)

        return render_template(
            "clustering/cluster_select.html",
            silhouette_scores=silhouette_scores,
            elbow_graph=elbow_path,
            session_id=session_id,
        )
    return render_template("clustering/upload_cluster.html")


@app.route("/kmeans-download", methods=["POST"])
def kmeans_download():
    num_clusters = int(request.form["num_clusters"])
    session_id = request.form["session_id"]
    filepath = os.path.join(app.config["UPLOAD_FOLDER"], f"{session_id}.csv")
    df = pd.read_csv(filepath)

    df_pre = preprocess_for_kmeans(df)

    model = KMeans(n_clusters=num_clusters, random_state=1)

    df["Cluster"] = model.fit_predict(df_pre)

    output = io.BytesIO()
    df.to_excel(output, index=False)
    output.seek(0)

    return send_file(
        output, download_name=f"clustered_k{num_clusters}.xlsx", as_attachment=True
    )


@app.route("/catboost-train", methods=["GET", "POST"])
def catboost_train():
    if request.method == "POST":
        print("\nüì• [DEBUG] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

        file = request.files["file"]
        if not file:
            print("‚ùå [DEBUG] ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå")
            return "No file uploaded", 400

        # Load file
        if file.filename.endswith(".csv"):
            df = pd.read_csv(file, dtype=str)  # ‚úÖ ‡πÉ‡∏ä‡πâ dtype=str
            print("üìÑ [DEBUG] ‡πÇ‡∏´‡∏•‡∏î CSV ‡πÅ‡∏•‡πâ‡∏ß df.head():")
            print(df.head())
            print("üîç dtypes ‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î:\n", df.dtypes)
        elif file.filename.endswith((".xlsx", ".xls")):
            df = pd.read_excel(file, dtype=str)
            print("üìÑ [DEBUG] ‡πÇ‡∏´‡∏•‡∏î Excel ‡πÅ‡∏•‡πâ‡∏ß df.head():")
            print(df.head())
            print("üîç dtypes ‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î:\n", df.dtypes)
        else:
            return "Unsupported file type", 400

        if "Cluster" not in df.columns:
            print("‚ùå [DEBUG] ‡πÑ‡∏°‡πà‡∏û‡∏ö column 'Cluster'")
            return "Missing 'Cluster' column in uploaded data", 400

        # Split features & label
        X = df.drop(columns=["Cluster"])
        y = df["Cluster"]
        print("\n‚úÖ [DEBUG] ‡πÅ‡∏¢‡∏Å X / y ‡πÅ‡∏•‡πâ‡∏ß:")
        print("üßæ X.columns:", list(X.columns))
        print("üéØ y ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:", y.head().tolist())

        # Detect categorical columns
        cat_features = X.select_dtypes(include=["object", "category"]).columns.tolist()
        print("\nüîé [DEBUG] cat_features ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö:", cat_features)

        # Convert only non-categorical columns
        for col in X.columns:
            if col not in cat_features:
                X[col] = pd.to_numeric(X[col], errors="coerce")

        print("\nüîÑ [DEBUG] dtypes ‡∏´‡∏•‡∏±‡∏á convert numeric columns:")
        print(X.dtypes)

        # Split data
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        print("\nüß™ [DEBUG] ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô:", X_train.shape)
        print("üß™ X_train.dtypes:\n", X_train.dtypes)
        print("üß™ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á X_train.head():\n", X_train.head())

        train_pool = Pool(X_train, y_train, cat_features=cat_features)



        # Train model
        print("\nüöÄ [DEBUG] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô CatBoostClassifier")
        model = CatBoostClassifier(
            depth=4,
            iterations=200,
            l2_leaf_reg=1,
            learning_rate=0.01,
            verbose=False
        )
        model.fit(train_pool)  # ‚úÖ ‡πÉ‡∏ä‡πâ Pool ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏ó‡∏ô
        print("‚úÖ [DEBUG] ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à")

        # Save model
        model_id = str(uuid.uuid4())
        model_dir = "static/models"
        os.makedirs(model_dir, exist_ok=True)
        model_path = f"{model_dir}/catboost_trained_{model_id}.pkl"
        joblib.dump(model, model_path)
        print("üíæ [DEBUG] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß:", model_path)

        # Save feature columns
        columns_path = f"{model_dir}/columns_{model_id}.json"
        with open(columns_path, "w") as f:
            json.dump(X.columns.tolist(), f)

        # Save cat values
        cat_values_map = {}
        for col in cat_features:
            cat_values_map[col] = sorted(df[col].dropna().unique().tolist())
        cat_values_path = f"{model_dir}/cat_values_{model_id}.json"
        with open(cat_values_path, "w") as f:
            json.dump(cat_values_map, f)

        # Save training data
        train_data_path = f"{model_dir}/train_data_{model_id}.csv"
        df.to_csv(train_data_path, index=False)
        print("üì¶ [DEBUG] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß:", train_data_path)

        # Export tree for Gemini
        print("\nüå≥ [DEBUG] ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á tree ‡∏à‡∏≤‡∏Å Pool")
        train_pool = Pool(X_train, y_train, cat_features=cat_features)

        print("üì¶ [DEBUG] ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Pool (X_train head):")
        print(X_train.head())

        graph = model.plot_tree(tree_idx=0, pool=train_pool)
        tree_text_path = f"{model_dir}/tree_text_{model_id}.txt"
        with open(tree_text_path, "w", encoding="utf-8") as f_out:
            f_out.write(graph.source)
        print("‚úÖ [DEBUG] export tree ‡πÄ‡∏™‡∏£‡πá‡∏à:", tree_text_path)

        return redirect(url_for("predict_now", model_id=model_id))

    return render_template("train_catboost/upload_catboost.html")



@app.route("/download-catboost-model/<filename>")
def download_catboost_model(filename):
    return send_file(f"static/models/{filename}", as_attachment=True) 


@app.route("/predict-now/<model_id>", methods=["GET", "POST"])
def predict_now(model_id):
    import json

    model_path = f"static/models/catboost_trained_{model_id}.pkl"
    columns_path = f"static/models/columns_{model_id}.json"
    cat_values_path = f"static/models/cat_values_{model_id}.json"
    tree_text_path = f"static/models/tree_text_{model_id}.txt"

    # Load columns
    if not os.path.exists(columns_path):
        return "Feature column file not found", 404
    with open(columns_path, "r") as f:
        feature_columns = json.load(f)

    # Load categorical values
    cat_values = {}
    if os.path.exists(cat_values_path):
        with open(cat_values_path, "r") as f:
            cat_values = json.load(f)
    cat_features = list(cat_values.keys())

    # Load model
    model = joblib.load(model_path)

    # Load pre-rendered tree text
    if not os.path.exists(tree_text_path):
        return "Tree explanation file not found", 404
    with open(tree_text_path, "r", encoding="utf-8") as f:
        dot_content = f.read()

    # Generate cluster explanation
    cluster_info = summarize_clusters_from_tree_with_gemini(dot_content, num_clusters=3)
    try:
        cluster_info_json = json.loads(cluster_info)
    except:
        cluster_info_json = None

    # Handle prediction
    result = None
    if request.method == "POST":
        input_data = {col: request.form[col] for col in feature_columns}
        df_input = pd.DataFrame([input_data])

        for col in df_input.columns:
            if col not in cat_features:
                try:
                    df_input[col] = pd.to_numeric(df_input[col])
                except:
                    pass

        result = model.predict(df_input)[0]

    return render_template(
        "predict/predict_now.html",
        model_id=model_id,
        columns=feature_columns,
        cat_values=cat_values,
        result=result,
        cluster_info=cluster_info_json
    )



@app.route("/", methods=["POST"])
def predict():

    num_clusters = request.form.get("num_clusters", "3")  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô 3

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    if "single_submit" in request.form:
        # ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏ü‡∏≠‡∏£‡πå‡∏°
        age = int(request.form["age"])
        unencoded_gender = request.form["gender"]
        # unencoded_gender = 'M'

        unencoded_education = request.form["education"]
        unencoded_marital = request.form["marital"]
        credit = float(request.form["credit"])
        trans_amt = float(request.form["trans_amt"])
        trans_count = float(request.form["trans_count"])
        months_on_book = float(request.form["MOB"])
        min_income = float(request.form["min-income"])
        max_income = float(request.form["max-income"])

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        input_data = {
            "Age": age,
            "Gender": unencoded_gender,
            "Education_Level": unencoded_education,
            "Marital_Status": unencoded_marital,
            "Months_on_book": months_on_book,
            "Credit_Limit": credit,
            "Total_Trans_Amt": trans_amt,
            "Total_Trans_Count": trans_count,
            "Min_income": min_income,
            "Max_income": max_income,
        }
        data = pd.DataFrame([input_data])

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå
    elif "file_submit" in request.form and "file" in request.files:
        file = request.files["file"]
        if file.filename != "":
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel
            data = pd.read_excel(file)

    else:
        return "Invalid input!", 400

    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
    model_path = f"catboost_kprototypes_{num_clusters}clusters.pkl"
    try:
        model = joblib.load(model_path)
    except FileNotFoundError:
        return f"Model for {num_clusters} clusters not found!", 500
    predictions = model.predict(data)

    # ‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
    tree_path = f"Tree_B_kp{num_clusters}.txt"
    with open(tree_path, "r", encoding="utf-8") as f:
        tree_text = f.read()

    # ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏™‡∏£‡∏∏‡∏õ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°
    # cluster_description = summarize_clusters_from_tree(tree_text, int(num_clusters))
    # cluster_description = summarize_clusters_from_tree_with_gemini(
    #     tree_text, int(num_clusters)
    # )
    cluster_info = summarize_clusters_from_tree_with_gemini(
        tree_text, int(num_clusters)
    )
    cluster_info_json = json.loads(cluster_info)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Cluster ‡πÉ‡∏ô DataFrame
    data["Cluster"] = predictions

    # ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô HTML ‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    tables = data.to_html(classes="data", header="true", index=False)

    # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á template
    return render_template(
        "resultPage.html",
        tables=tables,
        cluster_info=cluster_info_json,
        # cluster_description=cluster_description
    )


def preprocess_for_kmeans(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    # 1. ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå numerical ‡πÅ‡∏•‡∏∞ categorical
    numerical_cols = df.select_dtypes(include=["number"]).columns.tolist()
    categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()

    # 2. Scaling ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ numerical columns
    scaler = MinMaxScaler()
    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

    # 3. Factorize ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Categorical (‡πÑ‡∏°‡πà scale)
    for col in categorical_cols:
        df[col], _ = pd.factorize(df[col])

    return df


# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key
genai.configure(api_key="AIzaSyAc1bcSbtjbzgorjVVTCiuxNxhsdJDPNO8")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Gemini Model
model = genai.GenerativeModel("gemini-2.0-flash-lite")


def summarize_clusters_from_tree_with_gemini(tree_text, num_clusters):
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ AI

‡∏â‡∏±‡∏ô‡∏°‡∏µ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• CatBoost ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô {num_clusters} ‡∏Å‡∏•‡∏∏‡πà‡∏° (Cluster 0 ‡∏ñ‡∏∂‡∏á {num_clusters - 1})
‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ, ‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏Ø‡∏•‡∏Ø

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏° (Cluster) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å JSON ‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î ‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ '{{' ‡πÅ‡∏•‡∏∞‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ '}}' ‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:

{{
      "clusters": [
        {{
          "cluster": "Cluster 0",
          "group_name": "‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° (‡∏™‡∏±‡πâ‡∏ô‡πÜ 3-7 ‡∏Ñ‡∏≥)",
          "description": "‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ",
          "criteria": [
            "‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà 1 ‡πÄ‡∏ä‡πà‡∏ô Credit Limit ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 3000",
            "‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà 2 ‡πÄ‡∏ä‡πà‡∏ô Max Income ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 50000"
          ]
        }},
        {{
          "cluster": "Cluster 1",
          "group_name": "‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°",
          "description": "‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°",
          "criteria": [
            "‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà 1",
            "‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà 2"
          ]
        }}
        // Cluster ‡∏ï‡πà‡∏≠‡πÑ‡∏õ...
      ]
    }}

    ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°:
    {tree_text}

    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
"""

    response = model.generate_content(prompt)
    test_text = response.text.strip().replace("```", "")
    test_text = test_text.replace("json", "")
    print(test_text)
    return test_text if response.text else "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Gemini"


if __name__ == "__main__":
    app.run(port=3000, debug=True)
